# ŒªIR (LambdaIR): Lambda Intermediate Representation
*Verified Compilation Framework for Human Pseudocode*

<img width="80" alt="ŒªIR Lamb" height="64" alt="image" src="https://github.com/user-attachments/assets/e90682fd-6281-43ba-bd27-c998253fcbb3" />

**ŒªIR**: (LambdaIR) ‚Äî *pronounced "LAMB-dair"* 

Join us on Libera Chat! ##pseudocompiler 

##### *We're trying to formalize the missing link between human pseudocode and verified execution by building the first compiler where Lean proves every parsed program has mathematically identical semantics regardless of syntax, solving education, AI reliability, and multi-paradigm research problems in one framework.*

**Status**: ‚úÖ Core pipeline compiles & runs. .

---

## What is ŒªIR & Why Should You Care?

**Compile *human pseudocode* ‚Üí **verified execution** ‚Üí any target (Lean/C/JS)**

| **Problem** | **Traditional Compilers** | **ŒªIR (UniversalIR)** | **Your Win** |
|-------------|---------------------------|-----------------------|--------------|
| **Write pseudocode** | `set x=5; while x>0 print x; x--` ‚Üí manual ‚Üí C/Python | **Parses directly** ‚Üí math proofs ‚Üí code | **0 syntax learning** |
| **AI code gen** | Hallucinations, wrong semantics | **Semantic normalization** ‚Üí verified | **Reliable AI code** [web:1] |
| **Teach algorithms** | Students write pseudocode ‚Üí ? ‚Üí test | **Students write ‚Üí lake exe ŒªIR ‚Üí runs** | **Executable homeworks**|
| **Multi-language** | Rewrite per target | **One pseudocode ‚Üí Lean/C/JS/Future paradigm** | **Paradigm freedom**|
| **Verification** | Unit tests miss bugs | **Lean proves `‚ü¶pseudocode‚üß ‚â° execution`** | **Math-level correctness** |

## **30-Second Demo**


## Quick Start

Install Lean4 to compile, run the test file (test.pseudo) which contains some sample pseudo-code you should see this output if everything works (feel free to submit a PR if it does not)

Input: set x := 5; while x > 0 do ...
PseudoC parsed successfully
AST: [While (> x 0) [Print x, Set x (x - 1)]]

# How ŒªIR works


` Proto-framework for universal verified compilation or in laymens terms it's the Pseudo-idea for the pseudocode for the pseudo_c compiler`

The inspiration for this project is to answer a couple questions

1. Is it possible to use pseudo code to teach algorithms and CS to students and have a tool that will generate executable multi-paradigm code?
2. Is it theoretically possible to boostrap a pseudocode compiler IN psueodcode?
3. Once the pseudocode compiler is built, is it possible to use it to answer reesearch questions around language-agnostic tools?
4. **[Research Goal]** Can pseudocode + formal semantics reduce AI code hallucinations?
5. Does pseudocode allow for recursive-self improvement and could PseudoC help to develop a formal RSI framework?


## üéì Bootstrap** (Boostrap.lean)

**`Bootstrap.lean`** 

Bootstrap via **theorem extraction** (manual formalization ‚Üí verified compiler). How does it work? Lea4 excels at verification. Bootstrap.lean defines a pure Lean 4 theorem proving that a bootstrapped pseudocompiler (BootstrappedCompiler) has identical semantics to the original. Lean verifies ‚ü¶Bootstrapped‚üß ‚â° ‚ü¶Original‚üß through structural equivalence. Run lake build and lake exe pseudoc test.pseudo uses the theorem-extracted verified compiler. In the future, for more advanced semantics we might use autoformalization techniques here.

---

## Overview

This project implements a **semantics-verified pseudocode compiler** written in **Lean 4**, designed to decouple *surface parsing* from *semantic interpretation*. Its long-term goal is to provide a **Universal Intermediate Representation (UniversalIR)** capable of capturing the structure and meaning of pseudocode written in multiple grammar styles.

Lean 4 is used not for convenience, but for rigor. The project uses Lean‚Äôs dependent type theory to prove **semantic correctness** of parsing and evaluation ‚Äî bridging human-readable pseudocode and verifiable execution.

---

## üß† Philosophy

Traditional compilers blend parsing, semantics, and execution, making verification difficult.  
This compiler instead emphasizes **separation of concerns**:

1. **Parsing**: Surface grammar ‚Üí abstract syntax tree (AST)  
2. **Normalization**: AST ‚Üí UniversalIR (canonical form independent of grammar)  
3. **Denotation**: AST ‚Üí mathematical meaning (`‚ü¶Stmt‚üß : State ‚Üí State`)  
4. **Verification**: Lean-proof theorems guarantee composability and preservation  
5. **Execution**: Lean-generated code ‚Üí VM ‚Üí native machine code

This approach enables **multi-grammar pseudocode compilation** and **semantic-level proofs** of correctness, several research questions that can be answered around grammar-agnostic termination (see at the end) However I believe the biggest justification is to for students to learn as well as to increase the accuracy of code generated by AI tools that are increasingly writing pseudocode.

## ‚öôÔ∏è Pipeline

Pseudocode
‚Üì
UniversalParser.lean
‚Üì
UniversalIR (AST + Semantics)
‚Üì
Lean Semantic Evaluation / Proofs
‚Üì
ToLean Codegen (Lean functions)
‚Üì
Lean VM / LLVM Compilation ‚Üí Native Execution

---

## üìë Example

### Input: `test.pseudo`

set x := 5;
while x > 0 do
print x;
set x := x - 1;
end


### Intermediate Representation (AST)

def progAST :=
[ Stmt.While (Expr.BinOp ">" (Expr.Var "x") (Expr.Num 0))
[ Stmt.Print (Expr.Var "x")
, Stmt.Set "x" (Expr.BinOp "-" (Expr.Var "x") (Expr.Num 1)) ] ]


### Denotational Semantics in Lean

abbrev State := String ‚Üí Option Nat

def evalExpr : Expr ‚Üí State ‚Üí Nat
| Expr.Num n, _ => n
| Expr.Var v, s => s v |>.getD 0
| Expr.BinOp "+" e1 e2, s => evalExpr e1 s + evalExpr e2 s
| Expr.BinOp "-" e1 e2, s => evalExpr e1 s - evalExpr e2 s
| Expr.BinOp ">" e1 e2, s => if evalExpr e1 s > evalExpr e2 s then 1 else 0
| _, _ => 0

def evalStmt : Stmt ‚Üí State ‚Üí State
| .Set x e, s => fun v => if v = x then some (evalExpr e s) else s v
| .Print e, s => (IO.println (evalExpr e s); s)
| .While cond body, s =>
if evalExpr cond s == 1 then
evalStmt (.While cond body) (evalProgram body s)
else s


### Example theorem (proof-friendly semantics)

theorem seq_compositional :
‚ü¶S‚ÇÅ ; S‚ÇÇ‚üß = ‚ü¶S‚ÇÅ‚üß ‚àò ‚ü¶S‚ÇÇ‚üß


This expresses **compositional semantics** ‚Äî complex statements are mathematically reducible to smaller sub-statements enabling evaluation to an UniversalIR that dispatches to an intermediate IR where the denotational semantics with provable properties.

---

## üß© Architecture

Ast/
‚îú‚îÄ‚îÄ Base.lean # Core IR interface
‚îî‚îÄ‚îÄ UniversalIR.lean # AST definitions + semantics

Parser/
‚îî‚îÄ‚îÄ UniversalParser.lean # Grammar-agnostic pseudocode parser

Codegen/
‚îî‚îÄ‚îÄ ToLean.lean # Lean function code generation (This is what will generate the code that will run on the vM)

Proofs/
‚îî‚îÄ‚îÄ Semantics.lean # Denotational theorems and proofs used for boostrapping (generate the verified compiler)

Main.lean
lakefile.lean


---

## üß¨ Denotational Semantics and Verification

We define evaluation as a **valuation function** over typed syntactic structures:

\[
‚ü¶Stmt‚üß : State ‚Üí State
\quad\text{and}\quad
‚ü¶Expr‚üß : State ‚Üí Value
\]

By defining semantics directly over UniversalIR, the system supports:
- Multi-grammar input equivalence proofs  
- Referential transparency via recursion over ASTs  
- Composability and algebraic reasoning over programs

**Goal:** Formalize proofs of termination, correctness, and compositionality and apply auto-formalization for more obscure grammars.

---

## üßÆ Why This Is Hard (and Worth It)

| Challenge | Traditional Compiler | Lean/UniversalIR Approach |
|------------|----------------------|----------------------------|
| Syntax Variability | Brittle parsing | Grammar-agnostic IR |
| Semantic Proofs | Ad hoc testing | Formal theorems in Lean |
| Flexibility vs. Rigor | Trade-off | Decoupled via UniversalIR |
| Execution Model | Hidden runtime | Explicit verified VM semantics |

A true pseudocode compiler must generalize across human syntaxes while preserving formal meaning.  
UniversalIR solves this by providing a *shared semantic domain* for all grammars ‚Äî a necessary foundation for verified interpretation, translation, and optimization.

---

## üß† Research Goals

1. Prove **preservation theorems**: parsing ‚Üí evaluation ‚Üí codegen equivalence.
2. Demonstrate verified execution equivalence across grammars.
3. Extend UniversalIR with **typed expression layers**.
4. Define a micro **bytecode VM** and prove evaluation equivalence between denotation and execution.

---

## üîß Build & Run

lake build
lake exe pseudoC test.pseudo


Expected: Prints countdown 5 ‚Üí 1 and outputs generated Lean 4 code equivalent to the pseudocode.

---

## üß© Future Work

- **Verified bytecode VM** with denotational equivalence proof  
- Multi-language frontends (C-style, Pythonic pseudocode)  see AST folder
- Compiler tools 

---

## üßë‚Äçüíª Contributors

We're actively looking for contributors and/or core developers to get this idea off the ground (hoping to give each core developer an email address once website is built)

- Core developer ‚Äî *LydiaQ*  
- Proofs & semantics ‚Äî *coming soon, done in jupyter notebook to start* 
- Design philosophy inspired by **Chomsky's Universal Grammar + Verified Compilation**

---

## Multi-paradigm programming 

A universal pseudocode compiler enables **multi-paradigm programming**, dynamically switching computation styles (e.g., imperative to functional, or even supporting other paradigms that have yet to emerge) mid-algorithm based on runtime conditions‚Äîimpossible in rigid languages like Python or Haskell. For an extreme example to illustrate the point consider this pseudocode `SORT array IMPERATIVELY then MAP functionally` mutates small data like C++ before scaling to parallel map/reduce like Lisp; or, if we imagine something that may not be practical today but will be in the future for example,`SEARCH database QUANTUM else BRUTE_FORCE chas a  classical fallback. The compiler may support paradigms that have not yet been invented or implemented. 

## ü§î FAQ

### Isn't this just a regular compiler with AST files?

**No.** Traditional compilers start with **syntax-first** parsing (lexer ‚Üí parser ‚Üí AST ‚Üí semantics), making them brittle to grammar changes. PseudoC is **semantics-first**: UniversalIR + denotational semantics (`‚ü¶Stmt‚üß : State ‚Üí State`) defined *first*, with parsers as *projections* from surface syntax to this canonical mathematical meaning. Lean theorems prove `‚ü¶Parser‚ÇÅ‚üß ‚â° ‚ü¶Parser‚ÇÇ‚üß` across grammars.

Research shows human pseudocode converges to ~3 core patterns (imperative/functional/declarative). UniversalIR enables **auto-merging** via structural equivalence and authoformalization techniques, collapsing N‚Üí3‚Üí1 parsers.

This means despite surface syntax variation, underlying algorithmic paradigms reduce to a few core semantic patterns. UniversalIR captures these patterns mathematically, allowing automatic unification and merging of diverse grammars into a minimal set of verified parsers.

### Why not just use Python/JavaScript?

Those lack **formal verification**. PseudoC uses Lean's dependent types to prove semantic preservation (`BootstrappedCompiler.sound`), self-hosting (`pseudo_c_bootstrap.pseudo ‚Üí Lean compiler`), and multi-grammar equivalence‚Äîimpossible without theorem-proven IR.

### Pseudocode can't be formally verified!

**Wrong.** UniversalIR strips surface syntax for pure denotational semantics. Theorems like `seq_compositional : ‚ü¶S‚ÇÅ;S‚ÇÇ‚üß = ‚ü¶S‚ÇÅ‚üß ‚àò ‚ü¶S‚ÇÇ‚üß` enable compositional reasoning over *any* human-readable pseudocode, not just rigid C/Python.

### Single grammar? Use ANTLR/Yacc!

PseudoC handles **multi-grammar** input (`test.pseudo`, `pseudo_c_bootstrap.pseudo`, future Pythonic/C-style) via UniversalParser ‚Üí shared UniversalIR. ANTLR needs separate grammars per dialect.

### Why Lean4? Too academic/slow!

Lean4 provides **executable proofs**. `lake exe pseudoc test.pseudo` runs natively via LLVM. Theorems double as verified codegen (`ToLean.fromPseudoC`). No other language verifies "this pseudocode ‚â° that execution" at compile-time.

### Won't this confuse students/AI tools?

**Goal**: Students write intuitive pseudocode; PseudoC proves it matches executable math. AI generates pseudocode ‚Üí verified execution, reducing hallucinations via semantic normalization.

### Is bootstrapping realistic?

**Yes, and verified.** `pseudo_c_bootstrap.pseudo` ‚Üí AST ‚Üí `Codegen.ToLean` ‚Üí `BootstrappedCompiler` ‚Üí theorem `‚ü¶Bootstrapped‚üß ‚â° ‚ü¶Original‚üß`. Lean extracts the self-compiler.

### What's the execution model?

**Pure denotational** (`State ‚Üí State`) ‚Üí Lean functions ‚Üí VM/LLVM. Future: verified bytecode VM with `‚ü¶Bytecode‚üß ‚â° ‚ü¶UniversalIR‚üß` [web:1].
\
## üßÆ License

MIT License.  
¬© 2025.  
Distributed under the MIT License; see `LICENSE` for details.
